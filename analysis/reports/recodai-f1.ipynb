{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b78f8fb",
   "metadata": {
    "_cell_guid": "4cf02a6f-b7e9-4360-892d-b1a50793eb12",
    "_uuid": "2a1239f3-55fc-4dbb-9d3a-e90bfffa038c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-10-22T22:39:45.153848Z",
     "iopub.status.busy": "2025-10-22T22:39:45.153538Z",
     "iopub.status.idle": "2025-10-22T22:39:50.121355Z",
     "shell.execute_reply": "2025-10-22T22:39:50.120291Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.974349,
     "end_time": "2025-10-22T22:39:50.123178",
     "exception": false,
     "start_time": "2025-10-22T22:39:45.148829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "from numba import types\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def _rle_encode_jit(x: npt.NDArray, fg_val: int = 1) -> list[int]:\n",
    "    \"\"\"Numba-jitted RLE encoder.\"\"\"\n",
    "    dots = np.where(x.T.flatten() == fg_val)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def rle_encode(masks: list[npt.NDArray], fg_val: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Adapted from contrails RLE https://www.kaggle.com/code/inversion/contrails-rle-submission\n",
    "    Args:\n",
    "        masks: list of numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns: run length encodings as a string, with each RLE JSON-encoded and separated by a semicolon.\n",
    "    \"\"\"\n",
    "    return ';'.join([json.dumps(_rle_encode_jit(x, fg_val)) for x in masks])\n",
    "\n",
    "\n",
    "@numba.njit\n",
    "def _rle_decode_jit(mask_rle: npt.NDArray, height: int, width: int) -> npt.NDArray:\n",
    "    \"\"\"\n",
    "    s: numpy array of run-length encoding pairs (start, length)\n",
    "    shape: (height, width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    \"\"\"\n",
    "    if len(mask_rle) % 2 != 0:\n",
    "        # Numba requires raising a standard exception.\n",
    "        raise ValueError('One or more rows has an odd number of values.')\n",
    "\n",
    "    starts, lengths = mask_rle[0::2], mask_rle[1::2]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    for i in range(len(starts) - 1):\n",
    "        if ends[i] > starts[i + 1]:\n",
    "            raise ValueError('Pixels must not be overlapping.')\n",
    "    img = np.zeros(height * width, dtype=np.bool_)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def rle_decode(mask_rle: str, shape: tuple[int, int]) -> npt.NDArray:\n",
    "    \"\"\"\n",
    "    mask_rle: run-length as string formatted (start length)\n",
    "              empty predictions need to be encoded with '-'\n",
    "    shape: (height, width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    \"\"\"\n",
    "\n",
    "    mask_rle = json.loads(mask_rle)\n",
    "    mask_rle = np.asarray(mask_rle, dtype=np.int32)\n",
    "    starts = mask_rle[0::2]\n",
    "    if sorted(starts) != list(starts):\n",
    "        raise ParticipantVisibleError('Submitted values must be in ascending order.')\n",
    "    try:\n",
    "        return _rle_decode_jit(mask_rle, shape[0], shape[1]).reshape(shape, order='F')\n",
    "    except ValueError as e:\n",
    "        raise ParticipantVisibleError(str(e)) from e\n",
    "\n",
    "\n",
    "def calculate_f1_score(pred_mask: npt.NDArray, gt_mask: npt.NDArray):\n",
    "    pred_flat = pred_mask.flatten()\n",
    "    gt_flat = gt_mask.flatten()\n",
    "\n",
    "    tp = np.sum((pred_flat == 1) & (gt_flat == 1))\n",
    "    fp = np.sum((pred_flat == 1) & (gt_flat == 0))\n",
    "    fn = np.sum((pred_flat == 0) & (gt_flat == 1))\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    if (precision + recall) > 0:\n",
    "        return 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def calculate_f1_matrix(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray]):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    pred_masks (np.ndarray):\n",
    "            First dimension is the number of predicted instances.\n",
    "            Each instance is a binary mask of shape (height, width).\n",
    "    gt_masks (np.ndarray):\n",
    "            First dimension is the number of ground truth instances.\n",
    "            Each instance is a binary mask of shape (height, width).\n",
    "    \"\"\"\n",
    "\n",
    "    num_instances_pred = len(pred_masks)\n",
    "    num_instances_gt = len(gt_masks)\n",
    "    f1_matrix = np.zeros((num_instances_pred, num_instances_gt))\n",
    "\n",
    "    # Calculate F1 scores for each pair of predicted and ground truth masks\n",
    "    for i in range(num_instances_pred):\n",
    "        for j in range(num_instances_gt):\n",
    "            pred_flat = pred_masks[i].flatten()\n",
    "            gt_flat = gt_masks[j].flatten()\n",
    "            f1_matrix[i, j] = calculate_f1_score(pred_mask=pred_flat, gt_mask=gt_flat)\n",
    "\n",
    "    if f1_matrix.shape[0] < len(gt_masks):\n",
    "        # Add a row of zeros to the matrix if the number of predicted instances is less than ground truth instances\n",
    "        f1_matrix = np.vstack((f1_matrix, np.zeros((len(gt_masks) - len(f1_matrix), num_instances_gt))))\n",
    "\n",
    "    return f1_matrix\n",
    "\n",
    "\n",
    "def oF1_score(pred_masks: list[npt.NDArray], gt_masks: list[npt.NDArray]):\n",
    "    \"\"\"\n",
    "    Calculate the optimal F1 score for a set of predicted masks against\n",
    "    ground truth masks which considers the optimal F1 score matching.\n",
    "    This function uses the Hungarian algorithm to find the optimal assignment\n",
    "    of predicted masks to ground truth masks based on the F1 score matrix.\n",
    "    If the number of predicted masks is less than the number of ground truth masks,\n",
    "    it will add a row of zeros to the F1 score matrix to ensure that the dimensions match.\n",
    "\n",
    "    Parameters:\n",
    "    pred_masks (list of np.ndarray): List of predicted binary masks.\n",
    "    gt_masks (np.ndarray): Array of ground truth binary masks.\n",
    "    Returns:\n",
    "    float: Optimal F1 score.\n",
    "    \"\"\"\n",
    "    f1_matrix = calculate_f1_matrix(pred_masks, gt_masks)\n",
    "\n",
    "    # Find the best matching between predicted and ground truth masks\n",
    "    row_ind, col_ind = scipy.optimize.linear_sum_assignment(-f1_matrix)\n",
    "    # The linear_sum_assignment discards excess predictions so we need a separate penalty.\n",
    "    excess_predictions_penalty = len(gt_masks) / max(len(pred_masks), len(gt_masks))\n",
    "    return np.mean(f1_matrix[row_ind, col_ind]) * excess_predictions_penalty\n",
    "\n",
    "\n",
    "def evaluate_single_image(label_rles: str, prediction_rles: str, shape_str: str) -> float:\n",
    "    shape = json.loads(shape_str)\n",
    "    label_rles = [rle_decode(x, shape=shape) for x in label_rles.split(';')]\n",
    "    prediction_rles = [rle_decode(x, shape=shape) for x in prediction_rles.split(';')]\n",
    "    return oF1_score(prediction_rles, label_rles)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        solution (pd.DataFrame): The ground truth DataFrame.\n",
    "        submission (pd.DataFrame): The submission DataFrame.\n",
    "        row_id_column_name (str): The name of the column containing row IDs.\n",
    "    Returns:\n",
    "        float\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> solution = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['authentic', 'authentic', 'authentic'], 'shape': ['authentic', 'authentic', 'authentic']})\n",
    "    >>> submission = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['authentic', 'authentic', 'authentic']})\n",
    "    >>> score(solution.copy(), submission.copy(), row_id_column_name='row_id')\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['authentic', 'authentic', 'authentic'], 'shape': ['authentic', 'authentic', 'authentic']})\n",
    "    >>> submission = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 102]', '[101, 102]', '[101, 102]']})\n",
    "    >>> score(solution.copy(), submission.copy(), row_id_column_name='row_id')\n",
    "    0.0\n",
    "\n",
    "    >>> solution = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 102]', '[101, 102]', '[101, 102]'], 'shape': ['[720, 960]', '[720, 960]', '[720, 960]']})\n",
    "    >>> submission = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 102]', '[101, 102]', '[101, 102]']})\n",
    "    >>> score(solution.copy(), submission.copy(), row_id_column_name='row_id')\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 103]', '[101, 102]', '[101, 102]'], 'shape': ['[720, 960]', '[720, 960]', '[720, 960]']})\n",
    "    >>> submission = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 102]', '[101, 102]', '[101, 102]']})\n",
    "    >>> score(solution.copy(), submission.copy(), row_id_column_name='row_id')\n",
    "    0.9983739837398374\n",
    "\n",
    "    >>> solution = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 102];[300, 100]', '[101, 102]', '[101, 102]'], 'shape': ['[720, 960]', '[720, 960]', '[720, 960]']})\n",
    "    >>> submission = pd.DataFrame({'row_id': [0, 1, 2], 'annotation': ['[101, 102]', '[101, 102]', '[101, 102]']})\n",
    "    >>> score(solution.copy(), submission.copy(), row_id_column_name='row_id')\n",
    "    0.8333333333333334\n",
    "    \"\"\"\n",
    "    df = solution\n",
    "    df = df.rename(columns={'annotation': 'label'})\n",
    "\n",
    "    df['prediction'] = submission['annotation']\n",
    "    # Check for correct 'authentic' label\n",
    "    authentic_indices = (df['label'] == 'authentic') | (df['prediction'] == 'authentic')\n",
    "    df['image_score'] = ((df['label'] == df['prediction']) & authentic_indices).astype(float)\n",
    "\n",
    "    df.loc[~authentic_indices, 'image_score'] = df.loc[~authentic_indices].apply(\n",
    "        lambda row: evaluate_single_image(row['label'], row['prediction'], row['shape']), axis=1\n",
    "    )\n",
    "    return float(np.mean(df['image_score']))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.317653,
   "end_time": "2025-10-22T22:39:50.846278",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-22T22:39:40.528625",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
